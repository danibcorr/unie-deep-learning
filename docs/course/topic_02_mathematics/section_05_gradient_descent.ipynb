{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ac9364",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a59742",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Definición de la función\n",
    "\n",
    "\n",
    "def function(input: np.ndarray) -> np.ndarray:\n",
    "    assert input.shape[-1] == 2, \"La entrada debe contener 2 elementos\"\n",
    "    return np.sin(input[:, 0]) * np.cos(input[:, 1]) + np.sin(\n",
    "        0.5 * input[:, 0]\n",
    "    ) * np.cos(0.5 * input[:, 1])\n",
    "\n",
    "\n",
    "# Cálculo del gradiente (derivadas parciales)\n",
    "\n",
    "\n",
    "def gradiente(input: np.ndarray) -> np.ndarray:\n",
    "    assert input.shape[-1] == 2, \"La entrada debe contener 2 elementos\"\n",
    "\n",
    "    df_x1 = np.cos(input[:, 0]) * np.cos(input[:, 1]) + 0.5 * np.cos(\n",
    "        0.5 * input[:, 0]\n",
    "    ) * np.cos(0.5 * input[:, 1])\n",
    "    df_x2 = -np.sin(input[:, 0]) * np.sin(input[:, 1]) - 0.5 * np.sin(\n",
    "        0.5 * input[:, 0]\n",
    "    ) * np.sin(0.5 * input[:, 1])\n",
    "\n",
    "    return np.stack([df_x1, df_x2], axis=1)\n",
    "\n",
    "\n",
    "# Algoritmo de descenso del gradiente\n",
    "\n",
    "\n",
    "def descenso_gradiente(\n",
    "    num_puntos: int = 10, num_iteraciones: int = 30, learning_rate: float = 1e-3\n",
    "):\n",
    "    dim = 2\n",
    "    X = np.random.rand(num_puntos, dim) * 10  # Inicialización en el dominio [0,10]\n",
    "    trayectorias = [X.copy()]\n",
    "\n",
    "    for _ in range(num_iteraciones):\n",
    "        X = X - learning_rate * gradiente(input=X)\n",
    "        trayectorias.append(X.copy())\n",
    "\n",
    "    return np.array(trayectorias)\n",
    "\n",
    "\n",
    "# Ejecución del descenso del gradiente\n",
    "trayectoria = descenso_gradiente(num_puntos=5, num_iteraciones=30)\n",
    "\n",
    "# Visualización de trayectorias en el espacio 2D\n",
    "for i in range(trayectoria.shape[1]):\n",
    "    plt.plot(trayectoria[:, i, 0], trayectoria[:, i, 1], marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Trayectorias del descenso del gradiente\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad3852",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bcdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo = torch.arange(0, 20).float()\n",
    "tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocidad = torch.randn(20) * 3 + 0.75 * (tiempo - 9.5) ** 2 + 1\n",
    "plt.scatter(tiempo, velocidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa506a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocidad.shape, tiempo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73990bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion(instante_tiempo: torch.Tensor, parametros: torch.Tensor) -> float:\n",
    "    a, b, c = parametros\n",
    "    return a * (instante_tiempo**2) + (b * instante_tiempo) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa64594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(predicted: torch.Tensor, real: torch.Tensor) -> torch.Tensor:\n",
    "    return (real - predicted).square().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = torch.randn(3).requires_grad_()\n",
    "parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060dd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = funcion(instante_tiempo=tiempo, parametros=parametros)\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(tiempo, real, preds: torch.Tensor):\n",
    "    plt.scatter(tiempo, real, color=\"blue\", label=\"Real\")\n",
    "    plt.scatter(tiempo, preds.detach().cpu().numpy(), color=\"red\", label=\"Predicho\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_preds(tiempo, velocidad, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94884095",
   "metadata": {},
   "outputs": [],
   "source": [
    "perdida = loss_function(predicciones, velocidad)\n",
    "perdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae9a53",
   "metadata": {},
   "source": [
    "Aplicamos backward y comprobamos los gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perdida.backward()\n",
    "parametros.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb23d97",
   "metadata": {},
   "source": [
    "Podemos utilizar un ratio de aprendizaje, actualizar el gradiente a partir de ese ratio y volver a colocar 0 en los gradientes para realizar una nueva evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db415df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "parametros.data = parametros.data - lr * parametros.grad.data\n",
    "parametros.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6aecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = funcion(instante_tiempo=tiempo, parametros=parametros)\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5878e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds(tiempo, velocidad, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add00511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_step_training(tiempo, parametros_aprendibles, datos_a_predecir, lr=1e-5):\n",
    "    predicciones = funcion(instante_tiempo=tiempo, parametros=parametros_aprendibles)\n",
    "    perdida = loss_function(predicted=predicciones, real=datos_a_predecir)\n",
    "    perdida.backward()\n",
    "\n",
    "    # Hacerlo así es más seguro para actualizar los parámetros aprendibles\n",
    "    with torch.no_grad():\n",
    "        parametros_aprendibles -= lr * parametros_aprendibles.grad\n",
    "\n",
    "    # Otra forma de resetear los gradientes\n",
    "    parametros_aprendibles.grad.zero_()\n",
    "\n",
    "    show_preds(tiempo, datos_a_predecir, predicciones)\n",
    "    return predicciones, parametros_aprendibles, perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f77c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "parametros_aprendibles = torch.randn(3, requires_grad=True)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    predicciones, parametros_aprendibles, perdida = apply_step_training(\n",
    "        tiempo=tiempo,\n",
    "        parametros_aprendibles=parametros_aprendibles,\n",
    "        datos_a_predecir=velocidad,\n",
    "    )\n",
    "    print(f\"Epoch {epoch+1}, perdida: {perdida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(tensor_entrada: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    # (tensor_entrada) -> (B, N)\n",
    "    # peso -> (B, N, 1)\n",
    "    # (N)\n",
    "    return tensor_entrada @ w + b\n",
    "\n",
    "\n",
    "class CapaLineal:\n",
    "\n",
    "    def __init__(self, shape_entrada: int) -> None:\n",
    "\n",
    "        self.w = torch.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab6b41",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b77a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(data=torch.rand(1), requires_grad=True)\n",
    "        self.bias = nn.Parameter(data=torch.rand(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        return self.weight * input_tensor + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e28d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 1\n",
    "steps = 0.02\n",
    "X = np.arange(start, end, steps)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 0.3\n",
    "weight = 0.7\n",
    "y = weight * X + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4dc4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, c=\"b\", s=4, label=\"Training\")\n",
    "plt.show()\n",
    "plt.scatter(X_test, y_test, c=\"g\", s=4, label=\"Testing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9476888",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Linear()\n",
    "list(linear_model.parameters())\n",
    "linear_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = linear_model(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e91d2",
   "metadata": {},
   "source": [
    "De la documentacion: InferenceMode is analogous to no_grad and should be used when you are certain your operations will not interact with autograd (e.g., during data loading or model evaluation). Compared to no_grad, it removes additional overhead by disabling view tracking and version counter bumps. It is also more restrictive, in that tensors created in this mode cannot be used in computations recorded by autograd. Vamos que no tiene en cuenta el trackeo de los gradientes y lo hace más seguro para evitar la actualización de parámetros del modelo. A parte hace más rápida la ejecución de código en inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef609f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    predictions_2 = linear_model(X_test)\n",
    "predictions_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "plt.scatter(X_test, y_test, c=\"b\", s=4, label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs: int = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses_train = []\n",
    "    epoch_losses_test = []\n",
    "\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_model = linear_model(x)\n",
    "        loss = loss_fn(output_model, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses_train.append(loss.item())\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            output_model = linear_model(x)\n",
    "            loss = loss_fn(output_model, y)\n",
    "            epoch_losses_test.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1}, \"\n",
    "        f\"Train Loss: {np.mean(epoch_losses_train):.4f}, \"\n",
    "        f\"Test Loss: {np.mean(epoch_losses_test):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70339366",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    predictions_trained = linear_model(X_test)\n",
    "plt.scatter(X_test, predictions_trained, c=\"r\", s=4, label=\"Predictions\")\n",
    "plt.scatter(X_test, y_test, c=\"b\", s=4, label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model, \"linear_model.pth\")\n",
    "linear_model_loaded = torch.load(\"linear_model.pth\")\n",
    "linear_model_loaded.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    predictions_loaded = linear_model_loaded(X_test)\n",
    "plt.scatter(X_test, predictions_loaded, c=\"r\", s=4, label=\"Predictions\")\n",
    "plt.scatter(X_test, y_test, c=\"b\", s=4, label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unie-deep-learning (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
