{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99701cb4",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd3775",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b3a2f",
   "metadata": {},
   "source": [
    "## Deep Learning Layers Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13c7cc",
   "metadata": {},
   "source": [
    "### Local Reponse Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd498f45",
   "metadata": {},
   "source": [
    "La **Normalización de Respuesta Local (LRN, por sus siglas en inglés)** es una técnica introducida en las primeras arquitecturas de **redes neuronales convolucionales (CNNs)**, destacando especialmente en **AlexNet (2012)**. Su propósito principal es **mejorar la capacidad de generalización** del modelo y promover la **competencia entre neuronas** dentro de una misma capa convolucional.\n",
    "\n",
    "La LRN se inspira en los mecanismos biológicos de **inhibición lateral** observados en el sistema visual humano, particularmente en la retina. En este proceso biológico, la activación de una célula nerviosa inhibe la respuesta de las neuronas vecinas, lo que incrementa el contraste y mejora la percepción de bordes y detalles. De manera análoga, la LRN permite que una neurona con una activación alta **reduzca la magnitud de las activaciones de las neuronas cercanas**, resaltando así aquellas respuestas más relevantes y disminuyendo la redundancia entre filtros.\n",
    "\n",
    "El procedimiento de la LRN puede describirse del siguiente modo: para cada neurona activada, se considera un conjunto reducido de canales adyacentes (por ejemplo, los cinco canales circundantes). La activación de la neurona se **normaliza dividiéndola por un factor dependiente de la energía local**, es decir, de la suma de los cuadrados de las activaciones dentro de esa vecindad. En consecuencia, las neuronas con activaciones significativamente superiores a las de sus vecinas mantienen su valor elevado, mientras que aquellas con activaciones más bajas son atenuadas. Esta dinámica fomenta la especialización de los filtros y contribuye a una representación más discriminativa de las características.\n",
    "\n",
    "A pesar de su utilidad inicial, la LRN fue gradualmente **reemplazada por métodos de normalización más eficientes y estables**, tales como **Batch Normalization (BN)**, **Layer Normalization (LN)** e **Instance Normalization (IN)**. Estas técnicas ofrecen **mayor estabilidad numérica**, **aceleran el entrenamiento** y **mejoran el rendimiento general** de las redes profundas. En la práctica moderna, el uso de LRN es escaso, dado que las nuevas estrategias de normalización resultan **más simples, robustas y efectivas** en una amplia variedad de arquitecturas y contextos de aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df922182",
   "metadata": {},
   "source": [
    "Paper: https://www.cs.toronto.edu/~fritz/absps/imagenet.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a4da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e4ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LocalResponseNormalization(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, k: float = 2.0, n: int = 5, alpha: float = 1e-4, beta: float = 0.75\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        batch, channels, height, width = input_tensor.shape\n",
    "        response_normalization = input_tensor.clone()\n",
    "\n",
    "        for channel in range(channels):\n",
    "            for x in range(height):\n",
    "                for y in range(width):\n",
    "                    end_iterator = min(channels - 1, (channel + self.n) // 2)\n",
    "                    start_iterator = max(0, (channel - self.n) // 2)\n",
    "                    numerator = input_tensor[:, channel, x, y]\n",
    "                    denominator = (\n",
    "                        self.k\n",
    "                        + self.alpha\n",
    "                        * sum(\n",
    "                            (input_tensor[:, i, x, y] ** 2)\n",
    "                            for i in range(start_iterator, end_iterator + 1)\n",
    "                        )\n",
    "                    ) ** self.beta\n",
    "\n",
    "                    response_normalization[:, channel, x, y] = numerator / denominator\n",
    "\n",
    "        return response_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb84a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = LocalResponseNormalization()\n",
    "x = torch.randn(1, 10, 32, 32)\n",
    "y = lrn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ca024",
   "metadata": {},
   "source": [
    "### Global Response Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144c718",
   "metadata": {},
   "source": [
    "La **Global Response Normalization (GRN)** es una técnica reciente en el ámbito de la visión por computadora, introducida en el trabajo [*“ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders”*](https://arxiv.org/pdf/2301.00808).\n",
    "\n",
    "Esta técnica se incorpora como una capa de normalización global cuyo propósito principal es fomentar la competencia entre canales dentro de los mapas de características de las redes convolucionales. Su implementación busca mitigar el fenómeno conocido como *feature collapse*, frecuente en autoencoders enmascarados completamente convolucionales. El *feature collapse* ocurre cuando varios canales de una red neuronal presentan redundancia o pérdida de diversidad. En tales casos, algunos canales pueden generar activaciones constantes o saturarse, reduciendo la variabilidad de las representaciones internas y, en consecuencia, la calidad de las características aprendidas. GRN aborda este problema mediante un proceso de normalización y recalibración que equilibra las contribuciones de los distintos canales.\n",
    "\n",
    "El mecanismo de GRN se estructura en tres etapas fundamentales. Considerando un tensor de activaciones **X** con dimensiones **(N, C, H, W)**, correspondientes a tamaño de lote, número de canales, altura y anchura, el proceso se desarrolla de la siguiente manera:\n",
    "\n",
    "1. **Agregación global de características:**\n",
    "   Para cada canal *i*, se calcula una norma global (usualmente la norma $L_2$) a partir de todos los valores espaciales del mapa de características.\n",
    "   $$\n",
    "   G_i = \\sqrt{\\sum_{h,w} X_{i,h,w}^2}\n",
    "   $$\n",
    "   Este cálculo produce un vector **$G(X) = [G₁, G₂, …, G_C]$**, que representa la magnitud global de activación de cada canal.\n",
    "\n",
    "2. **Normalización intercanal:**\n",
    "   Posteriormente, los valores de norma se normalizan entre canales, dividiéndose cada uno por la media global de las normas o por otra estadística equivalente.\n",
    "   $$\n",
    "   N_i = \\frac{G_i}{\\mathrm{mean}(G(X)) + \\epsilon}\n",
    "   $$\n",
    "   Este paso genera un factor de ponderación relativo que indica la intensidad de activación de cada canal respecto al resto.\n",
    "\n",
    "3. **Recalibración de características y conexión residual:**\n",
    "   Cada canal del mapa de entrada se reescala multiplicándolo por su correspondiente factor normalizado (**Nᵢ**), aplicando además un escalado (**γ**) y un sesgo (**β**) aprendibles, junto con una conexión residual hacia la entrada original:\n",
    "   $$\n",
    "   \\text{Output}_i = \\gamma \\cdot (X_i \\cdot N_i) + \\beta + X_i\n",
    "   $$\n",
    "   Los parámetros **γ** y **β** se ajustan durante el entrenamiento y son específicos de cada canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf32a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalResponseNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels: int, eps: float = 1e-6) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "\n",
    "        self.gamma = nn.Parameter(data=torch.zeros(size=(1, self.num_channels, 1, 1)))\n",
    "        self.beta = nn.Parameter(data=torch.zeros(size=(1, self.num_channels, 1, 1)))\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        gx = torch.norm(input_tensor, p=2, dim=(2, 3), keepdim=True)\n",
    "        nx = gx / (gx.mean(dim=1, keepdim=True) + self.eps)\n",
    "\n",
    "        return self.gamma * (input_tensor * nx) + self.beta + input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d82f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 128, 32, 32)\n",
    "grn = GlobalResponseNormalization(x.shape[1])\n",
    "y = grn(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d007a",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132c614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization2D(nn.Module):\n",
    "    def __init__(self, num_channels: int, eps: float = 1e-6) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "\n",
    "        # For inference\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(1, num_channels, 1, 1))\n",
    "        self.register_buffer(\"running_std\", torch.ones(1, num_channels, 1, 1))\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # Input tensor -> (B, C, H, W) -> Batch norm is applied for each batch in H X W\n",
    "        mean = x.mean(dim=(0, 2, 3), keepdim=True)\n",
    "        std = x.std(dim=(0, 2, 3), keepdim=True)\n",
    "\n",
    "        self.running_mean = mean.detach()\n",
    "        self.running_std = std.detach()\n",
    "\n",
    "        return (x - mean) / (std + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035892f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 32, 32])\n",
      "torch.Size([8, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 128, 32, 32)\n",
    "bn = BatchNormalization2D(num_channels=x.shape[1]).train()\n",
    "y = bn(x)\n",
    "print(y.shape)\n",
    "\n",
    "bn.eval()\n",
    "with torch.no_grad():\n",
    "    y = bn(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1545ec8",
   "metadata": {},
   "source": [
    "### Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c399e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization2D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels: int, eps: float = 1e-6) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        mean = input_tensor.mean(dim=(1, 2, 3), keepdim=True)\n",
    "        std = input_tensor.mean(dim=(1, 2, 3), keepdim=True)\n",
    "\n",
    "        return (x - mean) / (std + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec6a2574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 128, 32, 32)\n",
    "ln = LayerNormalization2D(num_channels=x.shape[1]).train()\n",
    "y = ln(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805dfe6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unie-deep-learning (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
