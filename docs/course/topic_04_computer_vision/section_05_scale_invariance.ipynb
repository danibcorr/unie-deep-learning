{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210022d4",
   "metadata": {},
   "source": [
    "# Scale Invariance in Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12af48b",
   "metadata": {},
   "source": [
    "## Riesz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "class RieszLayer(Layer):\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, _, _, input_channels = input_shape\n",
    "        self.riesz_weights = self.add_weight(\n",
    "            shape=(5 * input_channels, self.output_channels),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True,\n",
    "            name=\"riesz_weights\",\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    @tf.function\n",
    "    def riesz_transform(self, input_image, H, W):\n",
    "        # Recompute frequency grids based on current input dimensions\n",
    "        n1 = tf.cast(\n",
    "            tf.signal.fftshift(tf.linspace(-H // 2, H // 2 - 1, H)), tf.float32\n",
    "        )\n",
    "        n2 = tf.cast(\n",
    "            tf.signal.fftshift(tf.linspace(-W // 2, W // 2 - 1, W)), tf.float32\n",
    "        )\n",
    "\n",
    "        n1 = tf.reshape(n1, (-1, 1))  # Column vector\n",
    "        n2 = tf.reshape(n2, (1, -1))  # Row vector\n",
    "        norm = tf.sqrt(n1**2 + n2**2 + 1e-8)\n",
    "\n",
    "        real_part_R1 = n1 / norm\n",
    "        imag_part_R1 = -tf.sqrt(1 - real_part_R1**2)\n",
    "        real_part_R2 = n2 / norm\n",
    "        imag_part_R2 = -tf.sqrt(1 - real_part_R2**2)\n",
    "\n",
    "        # Fourier transform of the input\n",
    "        I_hat = tf.signal.fft2d(tf.cast(input_image, tf.complex64))\n",
    "\n",
    "        # First-order Riesz transforms\n",
    "        I1 = tf.math.real(\n",
    "            tf.signal.ifft2d(I_hat * tf.complex(real_part_R1, imag_part_R1))\n",
    "        )\n",
    "        I2 = tf.math.real(\n",
    "            tf.signal.ifft2d(I_hat * tf.complex(real_part_R2, imag_part_R2))\n",
    "        )\n",
    "\n",
    "        # Second-order Riesz transforms\n",
    "        I_20 = tf.math.real(\n",
    "            tf.signal.ifft2d(I_hat * tf.complex(real_part_R1**2, imag_part_R1**2))\n",
    "        )\n",
    "        I_02 = tf.math.real(\n",
    "            tf.signal.ifft2d(I_hat * tf.complex(real_part_R2**2, imag_part_R2**2))\n",
    "        )\n",
    "        I_11 = tf.math.real(\n",
    "            tf.signal.ifft2d(\n",
    "                I_hat\n",
    "                * tf.complex(real_part_R1 * real_part_R2, imag_part_R1 * imag_part_R2)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return tf.stack([I1, I2, I_20, I_11, I_02], axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size, H, W, input_channels = (\n",
    "            tf.shape(inputs)[0],\n",
    "            tf.shape(inputs)[1],\n",
    "            tf.shape(inputs)[2],\n",
    "            tf.shape(inputs)[3],\n",
    "        )\n",
    "\n",
    "        # Reshape for channel-wise processing\n",
    "        inputs_reshaped = tf.reshape(inputs, (-1, H, W))  # Combine batch and channels\n",
    "\n",
    "        # Apply Riesz transform to each input slice using vectorization\n",
    "        riesz_transformed = tf.map_fn(\n",
    "            lambda x: self.riesz_transform(x, H, W),\n",
    "            inputs_reshaped,\n",
    "            fn_output_signature=tf.float32,\n",
    "        )\n",
    "\n",
    "        # Reshape back to original batch format with Riesz feature dimension\n",
    "        riesz_features = tf.reshape(\n",
    "            riesz_transformed, (batch_size, H, W, 5 * input_channels)\n",
    "        )\n",
    "\n",
    "        # Linear combination using weights\n",
    "        riesz_features_flat = tf.reshape(\n",
    "            riesz_features, (batch_size * H * W, 5 * input_channels)\n",
    "        )\n",
    "        combined_features_flat = tf.matmul(riesz_features_flat, self.riesz_weights)\n",
    "        combined_features = tf.reshape(\n",
    "            combined_features_flat, (batch_size, H, W, self.output_channels)\n",
    "        )\n",
    "\n",
    "        return combined_features\n",
    "\n",
    "\n",
    "# Verify functionality on a sample input with variable sizes\n",
    "sample_input_small = np.random.rand(1, 14, 14, 1).astype(np.float32)\n",
    "sample_input_large = np.random.rand(1, 56, 56, 1).astype(np.float32)\n",
    "\n",
    "print(\"Small input shape:\", sample_input_small.shape)\n",
    "transformed_output_small = RieszLayer(output_channels=5)(sample_input_small)\n",
    "print(\"Transformed output shape (small input):\", transformed_output_small.shape)\n",
    "\n",
    "print(\"Large input shape:\", sample_input_large.shape)\n",
    "transformed_output_large = RieszLayer(output_channels=5)(sample_input_large)\n",
    "print(\"Transformed output shape (large input):\", transformed_output_large.shape)\n",
    "\n",
    "\n",
    "# Helper function to resize the dataset\n",
    "def resize_dataset(images, target_size):\n",
    "    resized_images = np.array(\n",
    "        [cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) for img in images]\n",
    "    )\n",
    "    return np.expand_dims(resized_images, axis=-1)\n",
    "\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Add channel dimension (grayscale)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Resize images for evaluation at different scales\n",
    "x_test_small = resize_dataset(x_test[..., 0], (14, 14))\n",
    "x_test_large = resize_dataset(x_test[..., 0], (56, 56))\n",
    "\n",
    "\n",
    "# Define the neural network model using the functional API\n",
    "def create_riesz_cnn(input_shape=(None, None, 1)):\n",
    "    input_layer = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = RieszLayer(16, name=\"riesz_1\")(input_layer)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = RieszLayer(32, name=\"riesz_2\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = RieszLayer(40, name=\"riesz_3\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = RieszLayer(48, name=\"riesz_4\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    output = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "\n",
    "# Create the Riesz-based CNN model\n",
    "model = create_riesz_cnn(input_shape=(None, None, 1))\n",
    "\n",
    "# Compile the model with AdamW optimizer\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()  # Corrected typo from 'suummary' to 'summary'\n",
    "\n",
    "# Train the model with the learning rate scheduler\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "# Evaluate the model on different scales\n",
    "original_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "small_acc = model.evaluate(x_test_small, y_test, verbose=0)\n",
    "large_acc = model.evaluate(x_test_large, y_test, verbose=0)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy on original scale (28x28): {original_acc[1]:.4f}\")\n",
    "print(f\"Accuracy on smaller scale (14x14): {small_acc[1]:.4f}\")\n",
    "print(f\"Accuracy on larger scale (56x56): {large_acc[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
