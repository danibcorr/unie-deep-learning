{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image processing constitutes a fundamental tool in computer vision and deep learning.\n",
    "From a digital image, transformations are applied that allow modifying its visual\n",
    "properties, extracting relevant information, or preparing data for training artificial\n",
    "intelligence models. This text focuses on practical aspects of image processing in\n",
    "Python, primarily using NumPy, PIL (Python Imaging Library), OpenCV, and PyTorch.\n",
    "\n",
    "The necessary steps are described progressively to: load an image and represent it as a\n",
    "matrix; apply basic color and brightness transformations; introduce noise; mask specific\n",
    "regions; convert to grayscale; combine images through Mixup; and finally, perform\n",
    "resizing and normalization for use in convolutional neural networks (CNNs). All of this\n",
    "is integrated into a narrative oriented toward both conceptual and practical\n",
    "understanding of each operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Representing Images in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A digital color image is typically represented as a three-dimensional tensor of size\n",
    "$H \\times W \\times C$, where $H$ is the height (in pixels), $W$ is the width, and $C$ is\n",
    "the number of color channels, typically $C = 3$ for RGB images (red, green, blue). Each\n",
    "pixel is stored as an integer value in the range $[0, 255]$ of type `uint8`, which allows\n",
    "describing the intensity of each channel.\n",
    "\n",
    "In Python, it is common to load an image and convert it to a NumPy array to be able to\n",
    "manipulate it in a vectorized manner. The following shows how to perform this operation\n",
    "with PIL and OpenCV, and how to visualize the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Method 1: Using PIL (Python Imaging Library)\n",
    "image_pil = Image.open(\n",
    "    \"/home/dani/Repositorios/unie-deep-learning/docs/assets/course/topic_02_mathematics/cat_image.jpg\"\n",
    ")\n",
    "image_array = np.array(image_pil)\n",
    "\n",
    "# Method 2: Using OpenCV\n",
    "image_cv = cv2.imread(\n",
    "    \"/home/dani/Repositorios/unie-deep-learning/docs/assets/course/topic_02_mathematics/cat_image.jpg\"\n",
    ")\n",
    "image_cv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(image_array)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image dimensions: {image_array.shape}\")\n",
    "print(f\"Data type: {image_array.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `image_array` is a NumPy array with typical shape `(height, width, 3)` and\n",
    "data type `uint8`. The conversion from BGR to RGB in the case of OpenCV is necessary\n",
    "because OpenCV uses the BGR format by default, while most visualization libraries and PIL\n",
    "handle RGB.\n",
    "\n",
    "This matrix representation is the foundation upon which the image processing\n",
    "transformations described in subsequent sections are built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Transformations on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic transformations allow modifying properties such as saturation, brightness, or noise\n",
    "level, as well as masking specific regions or converting the image to grayscale. These\n",
    "operations are essential both for classical preprocessing and for generating synthetic\n",
    "data variations in data augmentation contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturation Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saturation controls the intensity of colors. An increase in saturation produces more\n",
    "vivid colors, while a decrease makes them more muted until reaching a grayscale image\n",
    "when saturation is null.\n",
    "\n",
    "In Python, a simple way to adjust saturation consists of using the `ImageEnhance` module\n",
    "from PIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "\n",
    "def cambiar_saturacion(image, factor=1.5):\n",
    "    \"\"\"\n",
    "    Factor > 1: Increases saturation.\n",
    "    Factor < 1: Decreases saturation.\n",
    "    Factor = 0: Grayscale image.\n",
    "    \"\"\"\n",
    "    image_pil = Image.fromarray(image)\n",
    "    enhancer = ImageEnhance.Color(image_pil)\n",
    "    image_saturada = enhancer.enhance(factor)\n",
    "    return np.array(image_saturada)\n",
    "\n",
    "\n",
    "# Usage examples\n",
    "imagen_mas_saturada = cambiar_saturacion(image_array, factor=2.0)\n",
    "imagen_menos_saturada = cambiar_saturacion(image_array, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagen_mas_saturada)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imagen_menos_saturada)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `factor` parameter controls the degree of modification. Values greater than 1 produce\n",
    "an increase in saturation, while values between 0 and 1 generate a progressively less\n",
    "saturated image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illumination Adjustment (Brightness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brightness reflects the global luminosity of the image. It can be modified through\n",
    "PIL-based techniques or through arithmetic operations with NumPy.\n",
    "\n",
    "A first approach, using `ImageEnhance.Brightness`, is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_brillo(image, factor=1.3):\n",
    "    \"\"\"\n",
    "    Factor > 1: Increases brightness.\n",
    "    Factor < 1: Decreases brightness.\n",
    "    \"\"\"\n",
    "    image_pil = Image.fromarray(image)\n",
    "    enhancer = ImageEnhance.Brightness(image_pil)\n",
    "    image_brillante = enhancer.enhance(factor)\n",
    "    return np.array(image_brillante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it is possible to adjust brightness directly with NumPy by adding a\n",
    "constant value to all pixels. In this case, it is important to avoid undesired\n",
    "saturations and maintain values in the valid range $[0, 255]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative with NumPy\n",
    "\n",
    "\n",
    "def ajustar_brillo_numpy(image, valor=50):\n",
    "    \"\"\"Add a constant value to all pixels.\"\"\"\n",
    "    image_ajustada = np.clip(image.astype(np.int16) + valor, 0, 255)\n",
    "    return image_ajustada.astype(np.uint8)\n",
    "\n",
    "\n",
    "# Usage examples\n",
    "imagen_mas_brillante = cambiar_brillo(image_array, factor=1.5)\n",
    "imagen_mas_oscura = cambiar_brillo(image_array, factor=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagen_mas_brillante)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imagen_mas_oscura)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NumPy version, temporary conversion to `int16` avoids overflow problems when\n",
    "adding positive values to a `uint8` array. The `np.clip` function guarantees that the\n",
    "result remains within the allowed limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of Gaussian Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise addition is a common technique in data augmentation to improve model robustness\n",
    "against perturbations. Gaussian noise is modeled through a normal distribution with mean\n",
    "$\\mu$ and standard deviation $\\sigma$, and is added to the value of each pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anadir_ruido_gaussiano(image, media=0, sigma=25):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the image.\n",
    "    sigma: Standard deviation of the noise (higher = more noise).\n",
    "    \"\"\"\n",
    "    ruido = np.random.normal(media, sigma, image.shape)\n",
    "    imagen_con_ruido = image.astype(np.float32) + ruido\n",
    "    imagen_con_ruido = np.clip(imagen_con_ruido, 0, 255)\n",
    "    return imagen_con_ruido.astype(np.uint8)\n",
    "\n",
    "\n",
    "# Usage example\n",
    "imagen_ruidosa = anadir_ruido_gaussiano(image_array, sigma=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagen_ruidosa)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A higher $\\sigma$ value increases noise intensity. As in the case of brightness, the\n",
    "operation is performed in floating point and the range is subsequently limited to obtain\n",
    "a valid image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking Image Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking consists of nullifying or modifying specific regions of the image, typically\n",
    "replacing them with a constant color. This procedure is useful for simulating occlusions,\n",
    "applying techniques like Cutout, or highlighting certain areas.\n",
    "\n",
    "Rectangular masking can be implemented directly by indexing rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enmascarar_region(image, x1, y1, x2, y2, color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Masks a rectangular region of the image.\n",
    "    Coordinates (x1, y1) and (x2, y2) define the upper left and lower right corners.\n",
    "    \"\"\"\n",
    "    imagen_enmascarada = image.copy()\n",
    "    imagen_enmascarada[y1:y2, x1:x2] = color\n",
    "    return imagen_enmascarada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, it is possible to mask a circular region using binary masks and OpenCV\n",
    "drawing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enmascarar_circular(image, centro, radio, color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Masks a circular region.\n",
    "    centro: Tuple (x, y) with the center of the circle.\n",
    "    radio: Radius of the circle in pixels.\n",
    "    \"\"\"\n",
    "    imagen_enmascarada = image.copy()\n",
    "    mascara = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mascara, centro, radio, 255, -1)\n",
    "    imagen_enmascarada[mascara == 0] = color\n",
    "    return imagen_enmascarada\n",
    "\n",
    "\n",
    "# Example: Mask the center of the image with a rectangle\n",
    "h, w = image_array.shape[:2]\n",
    "imagen_con_mascara = enmascarar_region(\n",
    "    image_array, w // 4, h // 4, 3 * w // 4, 3 * h // 4, color=(128, 128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagen_con_mascara)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of masking not only has value as an augmentation technique but also for\n",
    "focusing analysis on regions of interest or for hiding sensitive information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting an RGB image to grayscale reduces the three color channels to a single\n",
    "dimension of luminous intensity. There are various methods to perform this\n",
    "transformation. A simple approach uses PIL's native functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_blanco_negro(image):\n",
    "    \"\"\"Convert image to grayscale using PIL.\"\"\"\n",
    "    image_pil = Image.fromarray(image).convert(\"L\")\n",
    "    return np.array(image_pil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option consists of applying a weighted combination of the red, green, and blue\n",
    "channels. A widely used standard formula is:\n",
    "\n",
    "$$ I = 0.299 R + 0.587 G + 0.114 B $$\n",
    "\n",
    "where $R$, $G$, and $B$ represent the intensities of each channel. This expression is\n",
    "implemented in a vectorized manner with NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_bn_ponderado(image):\n",
    "    \"\"\"\n",
    "    Manual weighted conversion to grayscale.\n",
    "    Standard formula: 0.299*R + 0.587*G + 0.114*B.\n",
    "    \"\"\"\n",
    "    return np.dot(image[..., :3], [0.299, 0.587, 0.114]).astype(np.uint8)\n",
    "\n",
    "\n",
    "# Usage example\n",
    "imagen_bn = convertir_blanco_negro(image_array)\n",
    "plt.imshow(imagen_bn, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods generate a single-channel image that can be visualized through a grayscale\n",
    "color map. Grayscale conversion is used in applications where chromatic information is\n",
    "not essential or when reducing data dimensionality is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation: Importance and Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation increases the effective diversity of the training set without the need\n",
    "to acquire new images. This increase in variability contributes to reducing overfitting\n",
    "and improves model generalization capacity, especially when the number of original\n",
    "samples is limited.\n",
    "\n",
    "Augmentation strategies can be grouped into several categories. Geometric\n",
    "transformations, such as horizontal or vertical flips, rotations, cropping, or scaling,\n",
    "modify the spatial arrangement of content. This promotes model invariance to changes in\n",
    "orientation, translation, or scale.\n",
    "\n",
    "Color-based transformations alter the chromatic characteristics of the image, including\n",
    "adjustments to brightness, contrast, saturation, and hue. These operations seek\n",
    "robustness against variations in illumination, capture devices, or environmental\n",
    "conditions.\n",
    "\n",
    "Noise-based techniques introduce stochastic perturbations, such as Gaussian or impulse\n",
    "noise, that prepare the model for less ideal acquisition conditions. Advanced methods\n",
    "like Cutout consist of randomly masking image regions, forcing the network not to depend\n",
    "exclusively on small discriminative areas. Mixup, described earlier, linearly combines\n",
    "multiple images and their labels, generating intermediate examples in the feature space.\n",
    "\n",
    "Together, these augmentation strategies allow models to learn more robust representations\n",
    "that are less sensitive to irrelevant data variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Resizing and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks require input images to have fixed dimensions to be able to\n",
    "process them in batches and maintain a coherent structure throughout the convolutional\n",
    "layers. Standard values, such as $224 \\times 224$ pixels, are common in pretrained models\n",
    "(for example, in architectures trained on ImageNet), as they balance computational cost\n",
    "and sufficient spatial resolution to capture relevant details.\n",
    "\n",
    "Additionally, normalizing pixel intensities is essential for stabilizing training,\n",
    "ensuring that gradients are properly scaled, and facilitating optimizer convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing can be carried out in various ways, depending on whether one wishes to preserve\n",
    "the original aspect ratio, add padding, or crop the image. An example of a function that\n",
    "implements several strategies is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_size=(224, 224)):\n",
    "    \"\"\"Different resizing methods.\"\"\"\n",
    "\n",
    "    # Method 1: Simple resize (may distort aspect ratio)\n",
    "    resized_simple = cv2.resize(image, target_size)\n",
    "\n",
    "    # Method 2: Resize maintaining aspect ratio + padding\n",
    "    h, w = image.shape[:2]\n",
    "    target_h, target_w = target_size\n",
    "\n",
    "    scale = min(target_w / w, target_h / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "\n",
    "    resized = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    # Add padding to complete to target size\n",
    "    top = (target_h - new_h) // 2\n",
    "    bottom = target_h - new_h - top\n",
    "    left = (target_w - new_w) // 2\n",
    "    right = target_w - new_w - left\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0]\n",
    "    )\n",
    "\n",
    "    # Method 3: Center crop (only if the image is larger than the target)\n",
    "    if h > target_h or w > target_w:\n",
    "        start_h = (h - target_h) // 2\n",
    "        start_w = (w - target_w) // 2\n",
    "        cropped = image[start_h : start_h + target_h, start_w : start_w + target_w]\n",
    "    else:\n",
    "        cropped = image\n",
    "\n",
    "    return {\n",
    "        \"simple_resize\": resized_simple,\n",
    "        \"resize_with_padding\": padded,\n",
    "        \"center_crop\": cropped,\n",
    "    }\n",
    "\n",
    "\n",
    "# Usage example\n",
    "results = resize_image(image_array, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results[\"simple_resize\"])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(results[\"resize_with_padding\"])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(results[\"center_crop\"])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple resizing directly adjusts the image to the specified size but may distort geometry\n",
    "if the aspect ratio differs from the original. The approach that maintains the aspect\n",
    "ratio and adds padding avoids this distortion by adding uniform bands around the image.\n",
    "Finally, center cropping is useful when the image is larger and the most relevant\n",
    "information is considered to be near the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Preprocessing Pipeline for CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, preprocessing pipelines are defined that chain several transformations\n",
    "coherently. PyTorch, through the `torchvision.transforms` module, offers a compact way to\n",
    "define these workflows. The following shows a standard pipeline for models pretrained on\n",
    "ImageNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3pps\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Standard preprocessing pipeline for pretrained models\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # Resize to intermediate size\n",
    "        transforms.CenterCrop(224),  # Center crop to 224x224\n",
    "        transforms.ToTensor(),  # Convert to tensor [0, 1]\n",
    "        transforms.Normalize(  # Normalize with ImageNet mean and std\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ToTensor` transformation converts the image to a PyTorch tensor with shape\n",
    "$(C, H, W)$ and automatically normalizes values to the range $[0, 1]$. Subsequently,\n",
    "`Normalize` applies a channel-wise affine transformation:\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "where $\\mu$ is the mean and $\\sigma$ is the standard deviation of pixel values for each\n",
    "channel in the original training set (in this case, ImageNet). This normalization\n",
    "homogenizes the input data scale, which facilitates optimization.\n",
    "\n",
    "During training, data augmentation is typically incorporated directly into the pipeline,\n",
    "while during validation a more conservative set of transformations is employed, without\n",
    "randomness. A typical example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training with augmentation\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# For validation (without augmentation)\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training pipeline, `RandomResizedCrop` randomly selects a region from the original\n",
    "image and resizes it to $224 \\times 224$, varying both scale and position.\n",
    "`RandomHorizontalFlip` horizontally inverts the image with a predetermined probability,\n",
    "while `ColorJitter` randomly modifies brightness, contrast, and saturation within bounded\n",
    "ranges. In this way, each pass through the dataset generates slightly different versions\n",
    "of the original images, which increases the effective data diversity.\n",
    "\n",
    "In the validation pipeline, deterministic transformations are used to ensure that\n",
    "evaluations are reproducible and comparable across epochs. Size and normalization are\n",
    "kept consistent with the training pipeline, so that the model receives inputs in the same\n",
    "feature space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unie-deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
