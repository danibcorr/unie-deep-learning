{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Shift Invariance in Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## APS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Este clase implementa la capa APS de este paper: https://arxiv.org/abs/2011.14214\n",
    "\"\"\"\n",
    "\n",
    "# Standard libraries\n",
    "from typing import Literal\n",
    "\n",
    "# 3pps\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class AdaptivePolyphaseSampling(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        norm: int | float | Literal[\"fro\", \"nuc\", \"inf\", \"-inf\"] | None = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the class with normalization option.\n",
    "\n",
    "        Args:\n",
    "            norm: Normalization type or value, defaults to 2.\n",
    "        \"\"\"\n",
    "\n",
    "        # Constructor de la clase\n",
    "        super().__init__()\n",
    "\n",
    "        # Definimos los parámetros de la clase\n",
    "        self._stride = 2\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(\n",
    "        self, input_tensor: torch.Tensor, return_index: bool = False\n",
    "    ) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Processes input tensor to extract dominant polyphase component.\n",
    "\n",
    "        Args:\n",
    "            input_tensor: Tensor with shape (B, C, H, W).\n",
    "            return_index: If True, returns index of dominant component.\n",
    "\n",
    "        Returns:\n",
    "            Output tensor, optionally with index if return_index is True.\n",
    "        \"\"\"\n",
    "\n",
    "        # Tenemos a la entrada un tensor de (B, C, H, W)\n",
    "        # El número de componentes polifásicas coincide con el tamaño\n",
    "        # de paso elevado al cuadrado, porque nos vemos tanto en la\n",
    "        # altura como en la anchura , en total 4\n",
    "        poly_a = input_tensor[:, :, :: self._stride, :: self._stride]\n",
    "        poly_b = input_tensor[:, :, :: self._stride, 1 :: self._stride]\n",
    "        poly_c = input_tensor[:, :, 1 :: self._stride, :: self._stride]\n",
    "        poly_d = input_tensor[:, :, 1 :: self._stride, 1 :: self._stride]\n",
    "\n",
    "        # Combinamos las componentes en un solo tensor (B, P, C, H, W)\n",
    "        polyphase_combined = torch.stack((poly_a, poly_b, poly_c, poly_d), dim=1)\n",
    "\n",
    "        # Extraemos las dimensiones\n",
    "        b, p, _, _, _ = polyphase_combined.size()\n",
    "\n",
    "        # Combinamos los valores de los canales, altura y anchura del tensor\n",
    "        polyphase_combined_reshaped = torch.reshape(polyphase_combined, (b, p, -1))\n",
    "\n",
    "        # Aplicamos la norma a la última dimensión\n",
    "        polyphase_norms = torch.linalg.vector_norm(\n",
    "            input=polyphase_combined_reshaped, ord=self.norm, dim=(-1)\n",
    "        )\n",
    "\n",
    "        # Seleccionamos el componente polifásico de mayor orden\n",
    "        polyphase_max_norm = torch.argmax(polyphase_norms)\n",
    "\n",
    "        # Obtenemos el componente polifásico de mayor orden\n",
    "        output_tensor = polyphase_combined[:, polyphase_max_norm, ...]\n",
    "\n",
    "        # En el paper existe la opción de devolver el índice\n",
    "        if return_index:\n",
    "            return output_tensor, polyphase_max_norm\n",
    "\n",
    "        # En caso contrario solo devolvemos el tensor\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = AdaptivePolyphaseSampling()\n",
    "\n",
    "    x = torch.randn(1, 3, 4, 4)\n",
    "    output_model = model(x)\n",
    "\n",
    "    print(output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## LPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Este clase implementa la capa APS de este paper: https://arxiv.org/abs/2210.08001\n",
    "\"\"\"\n",
    "\n",
    "# 3pps\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class LearnablePolyphaseSampling(nn.Module):\n",
    "    def __init__(self, channel_size: int, hidden_size: int) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the model with specified channel and hidden sizes.\n",
    "\n",
    "        Args:\n",
    "            channel_size: Number of input channels for the Conv2D layer.\n",
    "            hidden_size: Number of hidden units for the Conv2D layer.\n",
    "        \"\"\"\n",
    "\n",
    "        # Constructor de la clase\n",
    "        super().__init__()\n",
    "\n",
    "        # Definimos los parámetros de la clase\n",
    "        self._stride = 2\n",
    "\n",
    "        # Definimos el modelo único para cada componente\n",
    "        self.conv_model = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=channel_size,\n",
    "                out_channels=hidden_size,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_size,\n",
    "                out_channels=hidden_size,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.Flatten(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, input_tensor: torch.Tensor, return_index: bool = False\n",
    "    ) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Processes input to extract dominant polyphase component.\n",
    "\n",
    "        Args:\n",
    "            input_tensor: Tensor with shape (B, C, H, W).\n",
    "            return_index: If True, returns index of dominant component.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of dominant component, optionally with index.\n",
    "        \"\"\"\n",
    "\n",
    "        # Tenemos a la entrada un tensor de (B, C, H, W)\n",
    "        # El número de componentes polifásicas coincide con el tamaño\n",
    "        # de paso elevado al cuadrado, porque nos vemos tanto en la\n",
    "        # altura como en la anchura , en total 4\n",
    "        poly_a = input_tensor[:, :, :: self._stride, :: self._stride]\n",
    "        poly_b = input_tensor[:, :, :: self._stride, 1 :: self._stride]\n",
    "        poly_c = input_tensor[:, :, 1 :: self._stride, :: self._stride]\n",
    "        poly_d = input_tensor[:, :, 1 :: self._stride, 1 :: self._stride]\n",
    "\n",
    "        # Combinamos las componentes en un solo tensor (B, P, C, H, W)\n",
    "        polyphase_combined = torch.stack((poly_a, poly_b, poly_c, poly_d), dim=1)\n",
    "\n",
    "        # Utilizamos el modelo basado en convoluciones por cada componente\n",
    "        _logits = []\n",
    "        for polyphase in range(polyphase_combined.size()[1]):\n",
    "            _logits.append(self.conv_model(polyphase_combined[:, polyphase, ...]))\n",
    "        logits = torch.squeeze(torch.stack(_logits))\n",
    "\n",
    "        # Aplicamos la norma a la última dimensión\n",
    "        polyphase_norms = F.gumbel_softmax(logits, tau=1, hard=False)\n",
    "\n",
    "        # Seleccionamos el componente polifásico de mayor orden\n",
    "        polyphase_max_norm = torch.argmax(polyphase_norms)\n",
    "\n",
    "        # Obtenemos el componente polifásico de mayor orden\n",
    "        output_tensor = polyphase_combined[:, polyphase_max_norm, ...]\n",
    "\n",
    "        # En el paper existe la opción de devolver el índice\n",
    "        if return_index:\n",
    "            return output_tensor, polyphase_max_norm\n",
    "\n",
    "        # En caso contrario solo devolvemos el tensor\n",
    "        return output_tensor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = LearnablePolyphaseSampling(channel_size=3, hidden_size=64)\n",
    "\n",
    "    x = torch.randn(1, 3, 4, 4)\n",
    "    output_model = model(x)\n",
    "\n",
    "    print(output_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
